{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748008f6-a35b-476e-b377-ff5a8bc00352",
   "metadata": {},
   "source": [
    "# Feature selection classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13d97c5-e032-49ff-b5fe-89bad35f2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\n",
    "from sksurv.util import Surv\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_selection import SelectorMixin, VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, Normalizer, RobustScaler, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import make_column_transformer, make_column_selector, ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRFClassifier, XGBRFRegressor\n",
    "\n",
    "class CoxnetSelector(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self,coef_threshold=0,**kwargs):\n",
    "        self.cns = CoxnetSurvivalAnalysis(**kwargs)\n",
    "        self.coef_threshold = coef_threshold\n",
    "        self.features_out = None\n",
    "        \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        nan = np.isnan(X).any(axis=1).values\n",
    "        notnan = np.where(~nan)[0]\n",
    "        self.cns.fit(X.iloc[notnan,:], y[notnan])\n",
    "        _keep = np.abs(self.cns.coef_[:,-1]) > self.coef_threshold\n",
    "        features_out = np.where(_keep)[0]\n",
    "        self.features_out = X.columns[features_out]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.loc[:,self.features_out]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        return np.array(self.features_out)\n",
    "    \n",
    "\n",
    "\n",
    "class VarianceSelector(TransformerMixin, BaseEstimator):        \n",
    "    def __init__(self, **kwargs):\n",
    "        self.vt = VarianceThreshold(**kwargs)\n",
    "        self.features_out = None\n",
    "        \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.vt.fit(X)\n",
    "        self.features_out = self.vt.get_feature_names_out()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        Xr = self.vt.transform(X)\n",
    "        return pd.DataFrame(Xr, columns=self.features_out, index=X.index)\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        return self.features_out\n",
    "\n",
    "\n",
    "class StandardTransform(TransformerMixin, BaseEstimator):\n",
    "    # scale a selection of features\n",
    "    def __init__(self, cols=None):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.cols = cols # columns to scale\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.cols is None:\n",
    "            self.cols = X.columns\n",
    "        self.scaler.fit(X[self.cols])\n",
    "        self.feature_names_in = X.columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xt = X.astype({col: 'float' for col in self.cols})\n",
    "        Xt.loc[:,self.cols] = self.scaler.transform(Xt[self.cols])\n",
    "        return Xt\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        return np.array(self.feature_names_in)\n",
    "\n",
    "\n",
    "class CorrelationSelector(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, threshold=0.95):\n",
    "        self.threshold = threshold\n",
    "        self.features_out = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        X1 = X.copy()\n",
    "        corr_matrix = X.corr()\n",
    "        col_corr = set() # correlated (deleted) columns\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if (abs(corr_matrix.iloc[i, j]) >= self.threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                    colname = corr_matrix.columns[i]\n",
    "                    col_corr.add(colname)\n",
    "                    if colname in X1.columns:\n",
    "                        del X1[colname]\n",
    "        self.features_out = X1.columns\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.loc[:, self.features_out]\n",
    "    \n",
    "    def get_feature_names_out(self):\n",
    "        return self.features_out\n",
    "\n",
    "\n",
    "class FrequencySelector(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, minfreq=0.05, mincount=np.Inf):\n",
    "        # default is to use frequency cutoff\n",
    "        self.minfreq = minfreq\n",
    "        self.mincount = mincount\n",
    "        self.features_out = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        counts = X.sum(axis=0)\n",
    "        freqs = counts / (~X.isna()).sum(axis=0)\n",
    "        n_max = (~X.isna()).sum(axis=0).max()\n",
    "        usecols = (counts >= self.mincount) if self.mincount/n_max < self.minfreq else freqs >= self.minfreq\n",
    "        self.features_out = np.array(X.columns[usecols])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.loc[:, self.features_out]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        return self.features_out\n",
    "\n",
    "\n",
    "class Log1pTransform(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self,):\n",
    "        self.features_out = None \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.features_out = X.columns\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        logX = np.log1p(X)\n",
    "        outX = pd.DataFrame(logX, index=X.index, columns=self.features_out)\n",
    "        return outX \n",
    "    \n",
    "    def get_feature_names_out(self):\n",
    "        return self.features_out\n",
    "    \n",
    "\n",
    "class PCATransform(TransformerMixin, BaseEstimator):\n",
    "    # accepts NA values unlike normal PCA\n",
    "    def __init__(self, prefix=None, **kwargs):\n",
    "        self.prefix = prefix if prefix else 'Unnamed_'\n",
    "        self.features_out = None\n",
    "        self.pca = PCA(**kwargs) # e.g. n_components\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        Xfull = X.dropna()\n",
    "        self.pca.fit(Xfull)\n",
    "        self.features_out = np.array([self.prefix + str(s) for s in self.pca.get_feature_names_out()])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        Xfull = X.dropna()\n",
    "        pcX = self.pca.transform(Xfull)\n",
    "        outX = pd.DataFrame(pcX, \n",
    "                            index=Xfull.index, \n",
    "                            columns=self.features_out).reindex(X.index)\n",
    "        return outX\n",
    "    \n",
    "    def get_feature_names_out(self):\n",
    "        return self.features_out\n",
    "class OrdEncoder(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, values=[-2, -1, 0, 1, 2]):\n",
    "        self.values = values\n",
    "        self.encoder = None \n",
    "        self.feature_names_out = None \n",
    "    \n",
    "    # encodes -2:0, -1:1, 0:2, 1:3, 2:4\n",
    "    # to comply with 0-based class label requirement XGBoost random forest classifier\n",
    "    def fit(self, X, y=None):\n",
    "        categories = [self.values for _ in range(X.shape[1])]\n",
    "        self.encoder = OrdinalEncoder(categories=categories,handle_unknown='use_encoded_value',unknown_value=np.nan).set_output(transform=\"pandas\")\n",
    "        self.feature_names_out = X.columns\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X):\n",
    "        Xout = self.encoder.fit_transform(X)\n",
    "        return Xout\n",
    "        \n",
    "    def get_feature_names_out(self):\n",
    "        return self.feature_names_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c2f133-f407-4333-843b-e5b94d6cb4dd",
   "metadata": {},
   "source": [
    "# Imports from main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66028bd-e0d7-4345-8ff1-f82c453fd526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# from main.py\n",
    "import os\n",
    "os.chdir('/home/users/nus/e1083772/cancer-survival-ml/')\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "shuffle=1\n",
    "fold=4\n",
    "endpoint='os'\n",
    "\n",
    "scratchdir=\"/scratch/users/nus/e1083772/cancer-survival-ml/data/splits\"\n",
    "features_file=f'{scratchdir}/{shuffle}/{fold}/train_features.parquet'\n",
    "features = pd.read_parquet(features_file)\n",
    "\n",
    "valid_features_file=f'{scratchdir}/{shuffle}/{fold}/valid_features.parquet'\n",
    "valid_features = pd.read_parquet(valid_features_file)\n",
    "\n",
    "survcols = [f'{endpoint}cdy',f'cens{endpoint}']\n",
    "train_surv_file=f'{scratchdir}/{shuffle}/{fold}/train_labels.parquet'\n",
    "train_surv = pd.read_parquet(train_surv_file,columns=survcols)\n",
    "train_surv.rename(columns={f'{endpoint}cdy':'survtime',f'cens{endpoint}':'survflag'},inplace=True)\n",
    "\n",
    "train_out_features_file=f'{scratchdir}/{shuffle}/{fold}/features_processed.parquet'\n",
    "valid_out_features_file=f'{scratchdir}/{shuffle}/{fold}/valid_features_processed.parquet'\n",
    "\n",
    "event = train_surv['survflag'].values\n",
    "time = train_surv.survtime\n",
    "offset = max(0, -np.min(time)) # some OS is negative\n",
    "print(offset)\n",
    "time += offset\n",
    "y = Surv.from_arrays(event,time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a67482-9882-4f49-8f4d-1c26d93ab457",
   "metadata": {},
   "source": [
    "# Feature selection on RNA-Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe63f353-8ecb-4644-9a27-b085ad6db65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = features.filter(regex='Feature_exp_')\n",
    "rna_cols = rna.columns\n",
    "cna = features.filter(regex='Feature_CNA_ENSG')\n",
    "cna_cols = cna.columns\n",
    "gistic = features.filter(regex='Feature_CNA_(Amp|Del)')\n",
    "gistic_cols = gistic.columns\n",
    "fish = features.filter(regex='Feature_fish')\n",
    "fish_cols = fish.columns\n",
    "clin = features.filter(regex='Feature_clin')\n",
    "clin_cols = clin.columns\n",
    "ig = features.filter(regex='Feature_SeqWGS')\n",
    "ig_cols = ig.columns\n",
    "sbs = features.filter(regex='Feature_SBS')\n",
    "sbs_cols = sbs.columns\n",
    "apobec = features.filter(regex='APOBEC')\n",
    "chromothripsis = features.filter(regex='chromothripsis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b21d7d",
   "metadata": {},
   "source": [
    "For debug\n",
    "\n",
    "Remove gene expression and copy number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "493c15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.filter(regex='Feature_(?!exp|CNA_ENSG)')\n",
    "valid_features = valid_features.filter(regex='Feature_(?!exp|CNA_ENSG)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5b040-f0d8-4013-94ce-f9dbc74b2b53",
   "metadata": {},
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33226c18-863f-4196-9aa9-5fcd36fdab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_gene_exp = Pipeline([\n",
    "    ('Non-zero variance', VarianceSelector(threshold=0)),\n",
    "    ('Log1p', Log1pTransform()),\n",
    "    ('Standard scaling', StandardTransform()),\n",
    "    ('Cox ElasticNet', CoxnetSelector(l1_ratio=0.5, coef_threshold=0.05)),\n",
    "])\n",
    "\n",
    "transformer_sbs = Pipeline([\n",
    "    ('Non-zero variance', VarianceSelector(threshold=1)),\n",
    "    ('Log1p', Log1pTransform()),\n",
    "    ('Standard scaling', StandardTransform()),\n",
    "    ('Cox LASSO', CoxnetSelector(l1_ratio=0.5, coef_threshold=0.1)),\n",
    "])\n",
    "\n",
    "transformer_gene_cn = Pipeline([\n",
    "    ('Non-zero variance', VarianceSelector(threshold=0)),\n",
    "    ('Coxnet', CoxnetSelector(l1_ratio=0.5, coef_threshold=0.05)),\n",
    "    ('Uncorrelated', CorrelationSelector(threshold=0.9)),\n",
    "])\n",
    "\n",
    "transformer_gistic = Pipeline([\n",
    "    ('Non-zero variance', VarianceSelector(threshold=0)),\n",
    "    ('Coxnet', CoxnetSelector(l1_ratio=0.5, coef_threshold = 0.2)),\n",
    "])\n",
    "\n",
    "transformer_fish = Pipeline([\n",
    "    ('Non-zero variance', VarianceSelector(threshold=0)),\n",
    "    ('Coxnet', CoxnetSelector(l1_ratio=0.5, coef_threshold = 0.2)),\n",
    "])\n",
    "\n",
    "transformer_clin = Pipeline([\n",
    "    ('Scale age', StandardTransform(cols=['Feature_clin_D_PT_age']))\n",
    "])\n",
    "\n",
    "transformer_ig = Pipeline([\n",
    "    ('Frequency', FrequencySelector(minfreq=0.01))\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('Gene expression', transformer_gene_exp, make_column_selector(pattern='Feature_exp_')),\n",
    "    ('Gene copy number', transformer_gene_cn, make_column_selector(pattern='Feature_CNA_ENSG')),\n",
    "    ('Gistic copy number', transformer_gistic, make_column_selector(pattern='Feature_CNA_(Amp|Del)')),\n",
    "    ('FISH copy number', transformer_fish, make_column_selector(pattern='Feature_fish')),\n",
    "    ('Mutation signatures', transformer_sbs, make_column_selector(pattern='Feature_SBS')),\n",
    "    ('Clinical', transformer_clin, make_column_selector(pattern='Feature_clin')),\n",
    "], remainder='passthrough').set_output(transform=\"pandas\")\n",
    "\n",
    "tree_args = {\n",
    "    'n_estimators': 1,\n",
    "    'subsample': 0.632,\n",
    "    'colsample_bynode': 0.632,\n",
    "    'n_jobs': 4,\n",
    "    'tree_method': 'hist',\n",
    "}\n",
    "\n",
    "imputer_args = {\n",
    "    'skip_complete':True\n",
    "}\n",
    "\n",
    "ContinuousImputer = IterativeImputer(estimator=XGBRFRegressor(**tree_args), initial_strategy='mean', **imputer_args)\n",
    "CategoricalImputer = IterativeImputer(estimator=XGBRFClassifier(**tree_args), initial_strategy='most_frequent', **imputer_args)\n",
    "\n",
    "imputer = ColumnTransformer([\n",
    "    ('Continuous variables', ContinuousImputer, make_column_selector(pattern='Feature_(exp|clin_D_PT_age|SBS)')),\n",
    "    ('Categorical variables', CategoricalImputer, make_column_selector(pattern='Feature_(?!exp|clin_D_PT_age|SBS)'))\n",
    "], remainder='drop').set_output(transform=\"pandas\")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('Feature selection', transformer),\n",
    "    ('Joint imputation', imputer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68c26d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/nus/e1083772/.localpython/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:1553: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  cols = cols[cols.str.contains(self.pattern, regex=True)]\n",
      "/home/users/nus/e1083772/.localpython/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:1553: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  cols = cols[cols.str.contains(self.pattern, regex=True)]\n"
     ]
    }
   ],
   "source": [
    "out = pipeline.fit_transform(features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bebc6b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 22)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.filter(regex='SBS').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c247d94-5c05-4532-8e34-2dbcec5d1c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 69)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.filter(regex='Gistic copy number').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52424d59-918a-46c0-99c1-2917af19a683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.filter(regex='Gene copy number').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "290b675a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.filter(regex='Gene expression').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14a86fb5-1fed-4207-8e9e-552e4fdf2152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 31)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.filter(regex='FISH copy number').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c4d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dab04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratchdir=\"/scratch/users/nus/e1083772/cancer-survival-ml/data/splits\"\n",
    "\n",
    "# train_out_features_file=f'{scratchdir}/{shuffle}/{fold}/features_subset.parquet'\n",
    "# valid_out_features_file=f'{scratchdir}/{shuffle}/{fold}/valid_features_subset.parquet'\n",
    "\n",
    "# out.to_parquet(train_out_features_file)\n",
    "# outv.to_parquet(valid_out_features_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
